# PRODIGY_GA_04

# Image -to - Image Translation with cGAN ðŸ¤–

This project implements image-to-image translation using a conditional Generative Adversarial Network (cGAN), specifically the pix2pix architecture. It leverages a U-Net-based generator and a convolutional discriminator to learn mappings between paired images, enabling tasks such as image colorization, style transfer, and domain adaptation with high visual fidelity.


## âœ“ Features:

â€¢ Generator and Discriminator architectures

â€¢ Loss functions combining adversarial and L1 loss

â€¢ Skip connections

â€¢ Upsampling



## concepts used:

â€¢ Conditional Generative Adversarial Network (cGAN), specifically the pix2pix architecture.

â€¢ Deep Learning with TensorFlow and Keras.

â€¢ U-Net-like generator architecture with skip connections.

â€¢ Generator and Discriminator models for image-to-image translation.

â€¢ Processing paired input and target images for supervised translation tasks.

â€¢ Loss functions: Adversarial (GAN) loss and L1 loss for better image quality.

â€¢ Key neural network components: Conv2D, LeakyReLU, BatchNormalization, Dropout, UpSampling2D, and Concatenate layers.



## Highlights:

â€¢ The use of U-Net-like generator

â€¢ LeakyReLU activations

â€¢ Batch normalization for stable and high-quality image generation
